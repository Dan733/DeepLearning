{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Function\n",
    "* used to approximate the reward based on a state\n",
    "* Q(s,a) calculates the expected future value from state **s** and action **a**\n",
    "* in DQN, we use a **neural network to approximate the reward**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes\n",
    "* Environment\n",
    "* Agent\n",
    "* Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas_datareader as pdr\n",
    "import datetime\n",
    "\n",
    "BUY = 'buy'\n",
    "SELL = 'sell'\n",
    "SKIP = 'skip'\n",
    "\n",
    "\n",
    "class Environment:\n",
    "    max_days_to_hold = 5\n",
    "    \n",
    "    def __init__(self, \n",
    "                 ticker, \n",
    "                 initial_deposit = 100000,\n",
    "                 from_date = datetime.datetime(2007, 1, 1), \n",
    "                 to_date = datetime.datetime(2017, 1, 1),\n",
    "                 window = 20):\n",
    "        self.initial_deposit = initial_deposit\n",
    "        self.window = window\n",
    "        self.data = pdr.get_data_google(ticker, from_date, to_date)\n",
    "        self.data_length = len(self.data)\n",
    "        \n",
    "        self.min_date = self.data.index.min()\n",
    "        self.max_date = self.data.index.max()\n",
    "        \n",
    "        self.action_space = [BUY, SELL, SKIP]\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.deposit = self.initial_deposit\n",
    "        self.current_index = self.window\n",
    "        return self.state()\n",
    "    \n",
    "    def score(self):\n",
    "        return self.deposit\n",
    "    \n",
    "    def enough_data_provided(self):\n",
    "        return self.current_index + Environment.max_days_to_hold <= self.data_length\n",
    "    \n",
    "    def _current_price(self):\n",
    "        return self.data.iloc[self.current_index]['Close']\n",
    "    \n",
    "    def state(self):\n",
    "        return self.data.iloc[self.current_index - self.window:self.current_index]['Close']\n",
    "        \n",
    "    def state_size(self):\n",
    "        return self.window\n",
    "    \n",
    "    def action_size(self):\n",
    "        return len(self.action_space)\n",
    "        \n",
    "    def step(self, action_tuple):\n",
    "        action = self.action_space[action_tuple[0]] # BUY, SELL, ...\n",
    "        value = action_tuple[1]                     # number of stocks to buy, always positive\n",
    "        days_to_hold = action_tuple[2]              # 1-5\n",
    "        \n",
    "        #print('\\t=> current action is: {} at {}'.format(action, self.data.index[self.current_index]))\n",
    "        \n",
    "        df = self.data.iloc[self.current_index: self.current_index + days_to_hold]['Close']\n",
    "        first_day_price = df.iloc[0]\n",
    "        last_day_price = df.iloc[-1]\n",
    "        \n",
    "        if action == BUY:\n",
    "            reward = last_day_price - first_day_price\n",
    "        elif action == SELL:\n",
    "            reward = first_day_price - last_day_price\n",
    "        elif action == SKIP:\n",
    "            reward = 0\n",
    "        \n",
    "        self.current_index += days_to_hold\n",
    "        self.deposit += reward*value\n",
    "        \n",
    "        next_state = self.state()\n",
    "        done = False\n",
    "        _ = None\n",
    "        return next_state, reward, done, _ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.update_target_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss=mean_squared_error,\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = self.model.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                a = self.model.predict(next_state)[0]\n",
    "                t = self.target_model.predict(next_state)[0]\n",
    "                target[0][action] = reward + self.gamma * t[np.argmax(a)]\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment('AAPL')\n",
    "state_size = env.state_size()\n",
    "action_size = env.action_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size, action_size)\n",
    "\n",
    "done = False\n",
    "batch_size = 32\n",
    "EPISODES = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/5000, score: 100714.0, e: 1.0\n",
      "episode: 1/5000, score: 101178.0, e: 0.99\n",
      "episode: 2/5000, score: 101858.0, e: 0.98\n",
      "episode: 3/5000, score: 97909.0, e: 0.97\n",
      "episode: 4/5000, score: 96943.0, e: 0.96\n",
      "episode: 5/5000, score: 96432.0, e: 0.95\n",
      "episode: 6/5000, score: 101860.0, e: 0.94\n",
      "episode: 7/5000, score: 98105.0, e: 0.93\n",
      "episode: 8/5000, score: 105870.0, e: 0.92\n",
      "episode: 9/5000, score: 97333.0, e: 0.91\n",
      "episode: 10/5000, score: 96074.0, e: 0.9\n",
      "episode: 11/5000, score: 93226.0, e: 0.9\n",
      "episode: 12/5000, score: 94052.0, e: 0.89\n",
      "episode: 13/5000, score: 99426.0, e: 0.88\n",
      "episode: 14/5000, score: 100624.0, e: 0.87\n",
      "episode: 15/5000, score: 98252.0, e: 0.86\n",
      "episode: 16/5000, score: 98694.0, e: 0.85\n",
      "episode: 17/5000, score: 100350.0, e: 0.84\n",
      "episode: 18/5000, score: 100209.0, e: 0.83\n",
      "episode: 19/5000, score: 101952.0, e: 0.83\n",
      "episode: 20/5000, score: 97315.0, e: 0.82\n",
      "episode: 21/5000, score: 102063.0, e: 0.81\n",
      "episode: 22/5000, score: 103399.0, e: 0.8\n",
      "episode: 23/5000, score: 99994.0, e: 0.79\n",
      "episode: 24/5000, score: 98826.0, e: 0.79\n",
      "episode: 25/5000, score: 100408.0, e: 0.78\n",
      "episode: 26/5000, score: 102384.0, e: 0.77\n",
      "episode: 27/5000, score: 104382.0, e: 0.76\n",
      "episode: 28/5000, score: 104781.0, e: 0.75\n",
      "episode: 29/5000, score: 92016.0, e: 0.75\n",
      "episode: 30/5000, score: 98601.0, e: 0.74\n",
      "episode: 31/5000, score: 101023.0, e: 0.73\n",
      "episode: 32/5000, score: 99428.0, e: 0.72\n",
      "episode: 33/5000, score: 103580.0, e: 0.72\n",
      "episode: 34/5000, score: 107014.0, e: 0.71\n",
      "episode: 35/5000, score: 98089.0, e: 0.7\n",
      "episode: 36/5000, score: 97097.0, e: 0.7\n",
      "episode: 37/5000, score: 103501.0, e: 0.69\n",
      "episode: 38/5000, score: 97875.0, e: 0.68\n",
      "episode: 39/5000, score: 99401.0, e: 0.68\n",
      "episode: 40/5000, score: 100601.0, e: 0.67\n",
      "episode: 41/5000, score: 97030.0, e: 0.66\n",
      "episode: 42/5000, score: 106010.0, e: 0.66\n",
      "episode: 43/5000, score: 100118.0, e: 0.65\n",
      "episode: 44/5000, score: 101394.0, e: 0.64\n",
      "episode: 45/5000, score: 104861.0, e: 0.64\n",
      "episode: 46/5000, score: 94813.0, e: 0.63\n",
      "episode: 47/5000, score: 97992.0, e: 0.62\n",
      "episode: 48/5000, score: 107218.0, e: 0.62\n",
      "episode: 49/5000, score: 97271.0, e: 0.61\n",
      "episode: 50/5000, score: 98414.0, e: 0.61\n",
      "episode: 51/5000, score: 100136.0, e: 0.6\n",
      "episode: 52/5000, score: 97653.0, e: 0.59\n",
      "episode: 53/5000, score: 94207.0, e: 0.59\n",
      "episode: 54/5000, score: 98100.0, e: 0.58\n",
      "episode: 55/5000, score: 94307.0, e: 0.58\n",
      "episode: 56/5000, score: 98576.0, e: 0.57\n",
      "episode: 57/5000, score: 99959.0, e: 0.56\n",
      "episode: 58/5000, score: 108058.0, e: 0.56\n",
      "episode: 59/5000, score: 95129.0, e: 0.55\n",
      "episode: 60/5000, score: 100202.0, e: 0.55\n",
      "episode: 61/5000, score: 99874.0, e: 0.54\n",
      "episode: 62/5000, score: 100117.0, e: 0.54\n",
      "episode: 63/5000, score: 106843.0, e: 0.53\n",
      "episode: 64/5000, score: 100662.0, e: 0.53\n",
      "episode: 65/5000, score: 98137.0, e: 0.52\n",
      "episode: 66/5000, score: 101659.0, e: 0.52\n",
      "episode: 67/5000, score: 102076.0, e: 0.51\n",
      "episode: 68/5000, score: 98784.0, e: 0.5\n",
      "episode: 69/5000, score: 93729.0, e: 0.5\n",
      "episode: 70/5000, score: 99914.0, e: 0.49\n",
      "episode: 71/5000, score: 99573.0, e: 0.49\n",
      "episode: 72/5000, score: 94585.0, e: 0.48\n",
      "episode: 73/5000, score: 105284.0, e: 0.48\n",
      "episode: 74/5000, score: 103689.0, e: 0.48\n",
      "episode: 75/5000, score: 95662.0, e: 0.47\n",
      "episode: 76/5000, score: 98944.0, e: 0.47\n",
      "episode: 77/5000, score: 98273.0, e: 0.46\n",
      "episode: 78/5000, score: 103772.0, e: 0.46\n",
      "episode: 79/5000, score: 102468.0, e: 0.45\n",
      "episode: 80/5000, score: 97608.0, e: 0.45\n",
      "episode: 81/5000, score: 99862.0, e: 0.44\n",
      "episode: 82/5000, score: 97400.0, e: 0.44\n",
      "episode: 83/5000, score: 98996.0, e: 0.43\n",
      "episode: 84/5000, score: 100017.0, e: 0.43\n",
      "episode: 85/5000, score: 109497.0, e: 0.43\n",
      "episode: 86/5000, score: 101372.0, e: 0.42\n",
      "episode: 87/5000, score: 104790.0, e: 0.42\n",
      "episode: 88/5000, score: 100713.0, e: 0.41\n",
      "episode: 89/5000, score: 100090.0, e: 0.41\n",
      "episode: 90/5000, score: 103190.0, e: 0.4\n",
      "episode: 91/5000, score: 105642.0, e: 0.4\n",
      "episode: 92/5000, score: 104139.0, e: 0.4\n",
      "episode: 93/5000, score: 101113.0, e: 0.39\n",
      "episode: 94/5000, score: 104995.0, e: 0.39\n",
      "episode: 95/5000, score: 98777.0, e: 0.38\n",
      "episode: 96/5000, score: 100148.0, e: 0.38\n",
      "episode: 97/5000, score: 103195.0, e: 0.38\n",
      "episode: 98/5000, score: 102845.0, e: 0.37\n",
      "episode: 99/5000, score: 106748.0, e: 0.37\n",
      "episode: 100/5000, score: 98749.0, e: 0.37\n",
      "episode: 101/5000, score: 98671.0, e: 0.36\n",
      "episode: 102/5000, score: 100575.0, e: 0.36\n",
      "episode: 103/5000, score: 102267.0, e: 0.36\n",
      "episode: 104/5000, score: 105788.0, e: 0.35\n",
      "episode: 105/5000, score: 102053.0, e: 0.35\n",
      "episode: 106/5000, score: 97461.0, e: 0.34\n",
      "episode: 107/5000, score: 111297.0, e: 0.34\n",
      "episode: 108/5000, score: 99484.0, e: 0.34\n",
      "episode: 109/5000, score: 106298.0, e: 0.33\n",
      "episode: 110/5000, score: 99419.0, e: 0.33\n",
      "episode: 111/5000, score: 98908.0, e: 0.33\n",
      "episode: 112/5000, score: 98590.0, e: 0.32\n",
      "episode: 113/5000, score: 103438.0, e: 0.32\n",
      "episode: 114/5000, score: 99121.0, e: 0.32\n",
      "episode: 115/5000, score: 93543.0, e: 0.31\n",
      "episode: 116/5000, score: 99404.0, e: 0.31\n",
      "episode: 117/5000, score: 101471.0, e: 0.31\n",
      "episode: 118/5000, score: 96145.0, e: 0.31\n",
      "episode: 119/5000, score: 104713.0, e: 0.3\n",
      "episode: 120/5000, score: 107255.0, e: 0.3\n",
      "episode: 121/5000, score: 98071.0, e: 0.3\n",
      "episode: 122/5000, score: 98797.0, e: 0.29\n",
      "episode: 123/5000, score: 95410.0, e: 0.29\n",
      "episode: 124/5000, score: 93566.0, e: 0.29\n",
      "episode: 125/5000, score: 108371.0, e: 0.28\n",
      "episode: 126/5000, score: 106747.0, e: 0.28\n",
      "episode: 127/5000, score: 101324.0, e: 0.28\n",
      "episode: 128/5000, score: 94481.0, e: 0.28\n",
      "episode: 129/5000, score: 97298.0, e: 0.27\n",
      "episode: 130/5000, score: 104674.0, e: 0.27\n",
      "episode: 131/5000, score: 101139.0, e: 0.27\n",
      "episode: 132/5000, score: 101572.0, e: 0.27\n",
      "episode: 133/5000, score: 92014.0, e: 0.26\n",
      "episode: 134/5000, score: 99375.0, e: 0.26\n",
      "episode: 135/5000, score: 93059.0, e: 0.26\n",
      "episode: 136/5000, score: 98886.0, e: 0.25\n",
      "episode: 137/5000, score: 103966.0, e: 0.25\n",
      "episode: 138/5000, score: 101186.0, e: 0.25\n",
      "episode: 139/5000, score: 95209.0, e: 0.25\n",
      "episode: 140/5000, score: 96089.0, e: 0.24\n",
      "episode: 141/5000, score: 104845.0, e: 0.24\n",
      "episode: 142/5000, score: 100766.0, e: 0.24\n",
      "episode: 143/5000, score: 98516.0, e: 0.24\n",
      "episode: 144/5000, score: 99150.0, e: 0.24\n",
      "episode: 145/5000, score: 90314.0, e: 0.23\n",
      "episode: 146/5000, score: 97434.0, e: 0.23\n",
      "episode: 147/5000, score: 106830.0, e: 0.23\n",
      "episode: 148/5000, score: 99767.0, e: 0.23\n",
      "episode: 149/5000, score: 95113.0, e: 0.22\n",
      "episode: 150/5000, score: 97713.0, e: 0.22\n",
      "episode: 151/5000, score: 103620.0, e: 0.22\n",
      "episode: 152/5000, score: 106730.0, e: 0.22\n",
      "episode: 153/5000, score: 94933.0, e: 0.21\n",
      "episode: 154/5000, score: 100167.0, e: 0.21\n",
      "episode: 155/5000, score: 103972.0, e: 0.21\n",
      "episode: 156/5000, score: 103253.0, e: 0.21\n",
      "episode: 157/5000, score: 97010.0, e: 0.21\n",
      "episode: 158/5000, score: 101584.0, e: 0.2\n",
      "episode: 159/5000, score: 100807.0, e: 0.2\n",
      "episode: 160/5000, score: 100906.0, e: 0.2\n",
      "episode: 161/5000, score: 101552.0, e: 0.2\n",
      "episode: 162/5000, score: 103854.0, e: 0.2\n",
      "episode: 163/5000, score: 102299.0, e: 0.19\n",
      "episode: 164/5000, score: 99459.0, e: 0.19\n",
      "episode: 165/5000, score: 103853.0, e: 0.19\n",
      "episode: 166/5000, score: 97328.0, e: 0.19\n",
      "episode: 167/5000, score: 104863.0, e: 0.19\n",
      "episode: 168/5000, score: 98114.0, e: 0.18\n",
      "episode: 169/5000, score: 104088.0, e: 0.18\n",
      "episode: 170/5000, score: 105817.0, e: 0.18\n",
      "episode: 171/5000, score: 99299.0, e: 0.18\n",
      "episode: 172/5000, score: 104495.0, e: 0.18\n",
      "episode: 173/5000, score: 99147.0, e: 0.18\n",
      "episode: 174/5000, score: 105253.0, e: 0.17\n",
      "episode: 175/5000, score: 104639.0, e: 0.17\n",
      "episode: 176/5000, score: 102253.0, e: 0.17\n",
      "episode: 177/5000, score: 103800.0, e: 0.17\n",
      "episode: 178/5000, score: 100235.0, e: 0.17\n",
      "episode: 179/5000, score: 92963.0, e: 0.17\n",
      "episode: 180/5000, score: 99648.0, e: 0.16\n",
      "episode: 181/5000, score: 92941.0, e: 0.16\n",
      "episode: 182/5000, score: 101213.0, e: 0.16\n",
      "episode: 183/5000, score: 104017.0, e: 0.16\n",
      "episode: 184/5000, score: 96071.0, e: 0.16\n",
      "episode: 185/5000, score: 100103.0, e: 0.16\n",
      "episode: 186/5000, score: 100014.0, e: 0.15\n",
      "episode: 187/5000, score: 104318.0, e: 0.15\n",
      "episode: 188/5000, score: 97847.0, e: 0.15\n",
      "episode: 189/5000, score: 104603.0, e: 0.15\n",
      "episode: 190/5000, score: 94787.0, e: 0.15\n",
      "episode: 191/5000, score: 92835.0, e: 0.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 192/5000, score: 107726.0, e: 0.15\n",
      "episode: 193/5000, score: 100529.0, e: 0.14\n",
      "episode: 194/5000, score: 106020.0, e: 0.14\n",
      "episode: 195/5000, score: 91049.0, e: 0.14\n",
      "episode: 196/5000, score: 99422.0, e: 0.14\n",
      "episode: 197/5000, score: 100104.0, e: 0.14\n",
      "episode: 198/5000, score: 101461.0, e: 0.14\n",
      "episode: 199/5000, score: 92552.0, e: 0.14\n",
      "episode: 200/5000, score: 94928.0, e: 0.13\n",
      "episode: 201/5000, score: 93185.0, e: 0.13\n",
      "episode: 202/5000, score: 98748.0, e: 0.13\n",
      "episode: 203/5000, score: 94170.0, e: 0.13\n",
      "episode: 204/5000, score: 98590.0, e: 0.13\n",
      "episode: 205/5000, score: 101407.0, e: 0.13\n",
      "episode: 206/5000, score: 98502.0, e: 0.13\n",
      "episode: 207/5000, score: 101324.0, e: 0.12\n",
      "episode: 208/5000, score: 100128.0, e: 0.12\n",
      "episode: 209/5000, score: 99340.0, e: 0.12\n",
      "episode: 210/5000, score: 98577.0, e: 0.12\n",
      "episode: 211/5000, score: 100696.0, e: 0.12\n",
      "episode: 212/5000, score: 102645.0, e: 0.12\n",
      "episode: 213/5000, score: 98156.0, e: 0.12\n",
      "episode: 214/5000, score: 101654.0, e: 0.12\n",
      "episode: 215/5000, score: 101814.0, e: 0.12\n",
      "episode: 216/5000, score: 93401.0, e: 0.11\n",
      "episode: 217/5000, score: 96575.0, e: 0.11\n",
      "episode: 218/5000, score: 99499.0, e: 0.11\n",
      "episode: 219/5000, score: 93862.0, e: 0.11\n",
      "episode: 220/5000, score: 100644.0, e: 0.11\n",
      "episode: 221/5000, score: 101852.0, e: 0.11\n",
      "episode: 222/5000, score: 101965.0, e: 0.11\n",
      "episode: 223/5000, score: 98910.0, e: 0.11\n",
      "episode: 224/5000, score: 104860.0, e: 0.11\n",
      "episode: 225/5000, score: 105822.0, e: 0.1\n",
      "episode: 226/5000, score: 94672.0, e: 0.1\n",
      "episode: 227/5000, score: 110147.0, e: 0.1\n",
      "episode: 228/5000, score: 103424.0, e: 0.1\n",
      "episode: 229/5000, score: 106444.0, e: 0.1\n",
      "episode: 230/5000, score: 96214.0, e: 0.099\n",
      "episode: 231/5000, score: 94870.0, e: 0.098\n",
      "episode: 232/5000, score: 96425.0, e: 0.097\n",
      "episode: 233/5000, score: 96241.0, e: 0.096\n",
      "episode: 234/5000, score: 100184.0, e: 0.095\n",
      "episode: 235/5000, score: 100403.0, e: 0.094\n",
      "episode: 236/5000, score: 102923.0, e: 0.093\n",
      "episode: 237/5000, score: 98364.0, e: 0.092\n",
      "episode: 238/5000, score: 100911.0, e: 0.091\n",
      "episode: 239/5000, score: 104739.0, e: 0.091\n",
      "episode: 240/5000, score: 100890.0, e: 0.09\n",
      "episode: 241/5000, score: 99776.0, e: 0.089\n",
      "episode: 242/5000, score: 96353.0, e: 0.088\n",
      "episode: 243/5000, score: 101082.0, e: 0.087\n",
      "episode: 244/5000, score: 97898.0, e: 0.086\n",
      "episode: 245/5000, score: 100906.0, e: 0.085\n",
      "episode: 246/5000, score: 103680.0, e: 0.084\n",
      "episode: 247/5000, score: 96430.0, e: 0.084\n",
      "episode: 248/5000, score: 101877.0, e: 0.083\n",
      "episode: 249/5000, score: 99719.0, e: 0.082\n",
      "episode: 250/5000, score: 95610.0, e: 0.081\n",
      "episode: 251/5000, score: 101867.0, e: 0.08\n",
      "episode: 252/5000, score: 102240.0, e: 0.079\n",
      "episode: 253/5000, score: 95026.0, e: 0.079\n",
      "episode: 254/5000, score: 102786.0, e: 0.078\n",
      "episode: 255/5000, score: 106186.0, e: 0.077\n",
      "episode: 256/5000, score: 98753.0, e: 0.076\n",
      "episode: 257/5000, score: 98189.0, e: 0.076\n",
      "episode: 258/5000, score: 99876.0, e: 0.075\n",
      "episode: 259/5000, score: 101690.0, e: 0.074\n",
      "episode: 260/5000, score: 102762.0, e: 0.073\n",
      "episode: 261/5000, score: 96228.0, e: 0.073\n",
      "episode: 262/5000, score: 98940.0, e: 0.072\n",
      "episode: 263/5000, score: 95376.0, e: 0.071\n",
      "episode: 264/5000, score: 96624.0, e: 0.07\n",
      "episode: 265/5000, score: 93265.0, e: 0.07\n",
      "episode: 266/5000, score: 95131.0, e: 0.069\n",
      "episode: 267/5000, score: 96370.0, e: 0.068\n",
      "episode: 268/5000, score: 95168.0, e: 0.068\n",
      "episode: 269/5000, score: 93417.0, e: 0.067\n",
      "episode: 270/5000, score: 98033.0, e: 0.066\n",
      "episode: 271/5000, score: 97724.0, e: 0.066\n",
      "episode: 272/5000, score: 97038.0, e: 0.065\n",
      "episode: 273/5000, score: 94230.0, e: 0.064\n",
      "episode: 274/5000, score: 95110.0, e: 0.064\n",
      "episode: 275/5000, score: 97043.0, e: 0.063\n",
      "episode: 276/5000, score: 101680.0, e: 0.062\n",
      "episode: 277/5000, score: 95137.0, e: 0.062\n",
      "episode: 278/5000, score: 94247.0, e: 0.061\n",
      "episode: 279/5000, score: 95003.0, e: 0.061\n",
      "episode: 280/5000, score: 96093.0, e: 0.06\n",
      "episode: 281/5000, score: 94964.0, e: 0.059\n",
      "episode: 282/5000, score: 93985.0, e: 0.059\n",
      "episode: 283/5000, score: 97798.0, e: 0.058\n",
      "episode: 284/5000, score: 96924.0, e: 0.058\n",
      "episode: 285/5000, score: 92713.0, e: 0.057\n",
      "episode: 286/5000, score: 94147.0, e: 0.056\n",
      "episode: 287/5000, score: 96286.0, e: 0.056\n",
      "episode: 288/5000, score: 96870.0, e: 0.055\n",
      "episode: 289/5000, score: 93711.0, e: 0.055\n",
      "episode: 290/5000, score: 98647.0, e: 0.054\n",
      "episode: 291/5000, score: 100302.0, e: 0.054\n",
      "episode: 292/5000, score: 97785.0, e: 0.053\n",
      "episode: 293/5000, score: 97231.0, e: 0.053\n",
      "episode: 294/5000, score: 95095.0, e: 0.052\n",
      "episode: 295/5000, score: 96994.0, e: 0.052\n",
      "episode: 296/5000, score: 97451.0, e: 0.051\n",
      "episode: 297/5000, score: 95151.0, e: 0.051\n",
      "episode: 298/5000, score: 101472.0, e: 0.05\n",
      "episode: 299/5000, score: 109002.0, e: 0.05\n",
      "episode: 300/5000, score: 99626.0, e: 0.049\n",
      "episode: 301/5000, score: 104639.0, e: 0.049\n",
      "episode: 302/5000, score: 96538.0, e: 0.048\n",
      "episode: 303/5000, score: 97044.0, e: 0.048\n",
      "episode: 304/5000, score: 96171.0, e: 0.047\n",
      "episode: 305/5000, score: 95567.0, e: 0.047\n",
      "episode: 306/5000, score: 103843.0, e: 0.046\n",
      "episode: 307/5000, score: 103290.0, e: 0.046\n",
      "episode: 308/5000, score: 105359.0, e: 0.045\n",
      "episode: 309/5000, score: 105097.0, e: 0.045\n",
      "episode: 310/5000, score: 96118.0, e: 0.044\n",
      "episode: 311/5000, score: 101087.0, e: 0.044\n",
      "episode: 312/5000, score: 103079.0, e: 0.043\n",
      "episode: 313/5000, score: 105380.0, e: 0.043\n",
      "episode: 314/5000, score: 100183.0, e: 0.043\n",
      "episode: 315/5000, score: 107730.0, e: 0.042\n",
      "episode: 316/5000, score: 94736.0, e: 0.042\n",
      "episode: 317/5000, score: 95691.0, e: 0.041\n",
      "episode: 318/5000, score: 102094.0, e: 0.041\n",
      "episode: 319/5000, score: 101206.0, e: 0.041\n",
      "episode: 320/5000, score: 101012.0, e: 0.04\n",
      "episode: 321/5000, score: 102278.0, e: 0.04\n",
      "episode: 322/5000, score: 100418.0, e: 0.039\n",
      "episode: 323/5000, score: 100906.0, e: 0.039\n",
      "episode: 324/5000, score: 101210.0, e: 0.039\n",
      "episode: 325/5000, score: 101897.0, e: 0.038\n",
      "episode: 326/5000, score: 100991.0, e: 0.038\n",
      "episode: 327/5000, score: 102753.0, e: 0.037\n",
      "episode: 328/5000, score: 103902.0, e: 0.037\n",
      "episode: 329/5000, score: 102773.0, e: 0.037\n",
      "episode: 330/5000, score: 103095.0, e: 0.036\n",
      "episode: 331/5000, score: 103195.0, e: 0.036\n",
      "episode: 332/5000, score: 102637.0, e: 0.036\n",
      "episode: 333/5000, score: 101974.0, e: 0.035\n",
      "episode: 334/5000, score: 102161.0, e: 0.035\n",
      "episode: 335/5000, score: 102138.0, e: 0.034\n",
      "episode: 336/5000, score: 105160.0, e: 0.034\n",
      "episode: 337/5000, score: 104420.0, e: 0.034\n",
      "episode: 338/5000, score: 102860.0, e: 0.033\n",
      "episode: 339/5000, score: 107044.0, e: 0.033\n",
      "episode: 340/5000, score: 105490.0, e: 0.033\n",
      "episode: 341/5000, score: 102264.0, e: 0.032\n",
      "episode: 342/5000, score: 105421.0, e: 0.032\n",
      "episode: 343/5000, score: 103779.0, e: 0.032\n",
      "episode: 344/5000, score: 105521.0, e: 0.032\n",
      "episode: 345/5000, score: 104345.0, e: 0.031\n",
      "episode: 346/5000, score: 104756.0, e: 0.031\n",
      "episode: 347/5000, score: 104095.0, e: 0.031\n",
      "episode: 348/5000, score: 106604.0, e: 0.03\n",
      "episode: 349/5000, score: 104771.0, e: 0.03\n",
      "episode: 350/5000, score: 104919.0, e: 0.03\n",
      "episode: 351/5000, score: 104499.0, e: 0.029\n",
      "episode: 352/5000, score: 105262.0, e: 0.029\n",
      "episode: 353/5000, score: 104173.0, e: 0.029\n",
      "episode: 354/5000, score: 102572.0, e: 0.029\n",
      "episode: 355/5000, score: 101889.0, e: 0.028\n",
      "episode: 356/5000, score: 104364.0, e: 0.028\n",
      "episode: 357/5000, score: 102714.0, e: 0.028\n",
      "episode: 358/5000, score: 104851.0, e: 0.027\n",
      "episode: 359/5000, score: 102523.0, e: 0.027\n",
      "episode: 360/5000, score: 103563.0, e: 0.027\n",
      "episode: 361/5000, score: 103343.0, e: 0.027\n",
      "episode: 362/5000, score: 101791.0, e: 0.026\n",
      "episode: 363/5000, score: 104343.0, e: 0.026\n",
      "episode: 364/5000, score: 102667.0, e: 0.026\n",
      "episode: 365/5000, score: 104058.0, e: 0.026\n",
      "episode: 366/5000, score: 101438.0, e: 0.025\n",
      "episode: 367/5000, score: 105824.0, e: 0.025\n",
      "episode: 368/5000, score: 104935.0, e: 0.025\n",
      "episode: 369/5000, score: 105740.0, e: 0.025\n",
      "episode: 370/5000, score: 104022.0, e: 0.024\n",
      "episode: 371/5000, score: 105711.0, e: 0.024\n",
      "episode: 372/5000, score: 108001.0, e: 0.024\n",
      "episode: 373/5000, score: 105082.0, e: 0.024\n",
      "episode: 374/5000, score: 103718.0, e: 0.023\n",
      "episode: 375/5000, score: 105041.0, e: 0.023\n",
      "episode: 376/5000, score: 98930.0, e: 0.023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 377/5000, score: 101464.0, e: 0.023\n",
      "episode: 378/5000, score: 104731.0, e: 0.022\n",
      "episode: 379/5000, score: 104422.0, e: 0.022\n",
      "episode: 380/5000, score: 104783.0, e: 0.022\n",
      "episode: 381/5000, score: 105440.0, e: 0.022\n",
      "episode: 382/5000, score: 104741.0, e: 0.022\n",
      "episode: 383/5000, score: 104138.0, e: 0.021\n",
      "episode: 384/5000, score: 107424.0, e: 0.021\n",
      "episode: 385/5000, score: 104524.0, e: 0.021\n",
      "episode: 386/5000, score: 105567.0, e: 0.021\n",
      "episode: 387/5000, score: 105689.0, e: 0.02\n",
      "episode: 388/5000, score: 105013.0, e: 0.02\n",
      "episode: 389/5000, score: 104013.0, e: 0.02\n",
      "episode: 390/5000, score: 105830.0, e: 0.02\n",
      "episode: 391/5000, score: 106064.0, e: 0.02\n",
      "episode: 392/5000, score: 107007.0, e: 0.019\n",
      "episode: 393/5000, score: 105943.0, e: 0.019\n",
      "episode: 394/5000, score: 106120.0, e: 0.019\n",
      "episode: 395/5000, score: 105518.0, e: 0.019\n",
      "episode: 396/5000, score: 105517.0, e: 0.019\n",
      "episode: 397/5000, score: 104718.0, e: 0.019\n",
      "episode: 398/5000, score: 105806.0, e: 0.018\n",
      "episode: 399/5000, score: 105475.0, e: 0.018\n",
      "episode: 400/5000, score: 105652.0, e: 0.018\n",
      "episode: 401/5000, score: 105092.0, e: 0.018\n",
      "episode: 402/5000, score: 105018.0, e: 0.018\n",
      "episode: 403/5000, score: 104589.0, e: 0.017\n",
      "episode: 404/5000, score: 104143.0, e: 0.017\n",
      "episode: 405/5000, score: 105293.0, e: 0.017\n",
      "episode: 406/5000, score: 104739.0, e: 0.017\n",
      "episode: 407/5000, score: 105251.0, e: 0.017\n",
      "episode: 408/5000, score: 105385.0, e: 0.017\n",
      "episode: 409/5000, score: 104739.0, e: 0.016\n",
      "episode: 410/5000, score: 105248.0, e: 0.016\n",
      "episode: 411/5000, score: 104176.0, e: 0.016\n",
      "episode: 412/5000, score: 104407.0, e: 0.016\n",
      "episode: 413/5000, score: 105541.0, e: 0.016\n",
      "episode: 414/5000, score: 106748.0, e: 0.016\n",
      "episode: 415/5000, score: 105073.0, e: 0.015\n",
      "episode: 416/5000, score: 105207.0, e: 0.015\n",
      "episode: 417/5000, score: 105504.0, e: 0.015\n",
      "episode: 418/5000, score: 104911.0, e: 0.015\n",
      "episode: 419/5000, score: 104804.0, e: 0.015\n",
      "episode: 420/5000, score: 104895.0, e: 0.015\n",
      "episode: 421/5000, score: 105475.0, e: 0.015\n",
      "episode: 422/5000, score: 106180.0, e: 0.014\n",
      "episode: 423/5000, score: 105622.0, e: 0.014\n",
      "episode: 424/5000, score: 106595.0, e: 0.014\n",
      "episode: 425/5000, score: 105948.0, e: 0.014\n",
      "episode: 426/5000, score: 106011.0, e: 0.014\n",
      "episode: 427/5000, score: 105144.0, e: 0.014\n",
      "episode: 428/5000, score: 105390.0, e: 0.014\n",
      "episode: 429/5000, score: 105872.0, e: 0.013\n",
      "episode: 430/5000, score: 105260.0, e: 0.013\n",
      "episode: 431/5000, score: 105952.0, e: 0.013\n",
      "episode: 432/5000, score: 105415.0, e: 0.013\n",
      "episode: 433/5000, score: 107054.0, e: 0.013\n",
      "episode: 434/5000, score: 105581.0, e: 0.013\n",
      "episode: 435/5000, score: 104890.0, e: 0.013\n",
      "episode: 436/5000, score: 106268.0, e: 0.013\n",
      "episode: 437/5000, score: 105083.0, e: 0.012\n",
      "episode: 438/5000, score: 105011.0, e: 0.012\n",
      "episode: 439/5000, score: 105599.0, e: 0.012\n",
      "episode: 440/5000, score: 105137.0, e: 0.012\n",
      "episode: 441/5000, score: 105094.0, e: 0.012\n",
      "episode: 442/5000, score: 105142.0, e: 0.012\n",
      "episode: 443/5000, score: 105263.0, e: 0.012\n",
      "episode: 444/5000, score: 105642.0, e: 0.012\n",
      "episode: 445/5000, score: 105538.0, e: 0.011\n",
      "episode: 446/5000, score: 105299.0, e: 0.011\n",
      "episode: 447/5000, score: 105856.0, e: 0.011\n",
      "episode: 448/5000, score: 105018.0, e: 0.011\n",
      "episode: 449/5000, score: 105624.0, e: 0.011\n",
      "episode: 450/5000, score: 104624.0, e: 0.011\n",
      "episode: 451/5000, score: 105760.0, e: 0.011\n",
      "episode: 452/5000, score: 106019.0, e: 0.011\n",
      "episode: 453/5000, score: 104354.0, e: 0.011\n",
      "episode: 454/5000, score: 105071.0, e: 0.01\n",
      "episode: 455/5000, score: 104828.0, e: 0.01\n",
      "episode: 456/5000, score: 106081.0, e: 0.01\n",
      "episode: 457/5000, score: 105676.0, e: 0.01\n",
      "episode: 458/5000, score: 105462.0, e: 0.01\n",
      "episode: 459/5000, score: 105259.0, e: 0.0099\n",
      "episode: 460/5000, score: 105404.0, e: 0.0099\n",
      "episode: 461/5000, score: 105545.0, e: 0.0099\n",
      "episode: 462/5000, score: 105870.0, e: 0.0099\n",
      "episode: 463/5000, score: 105727.0, e: 0.0099\n",
      "episode: 464/5000, score: 105133.0, e: 0.0099\n",
      "episode: 465/5000, score: 103738.0, e: 0.0099\n",
      "episode: 466/5000, score: 104256.0, e: 0.0099\n",
      "episode: 467/5000, score: 105160.0, e: 0.0099\n",
      "episode: 468/5000, score: 104677.0, e: 0.0099\n",
      "episode: 469/5000, score: 105774.0, e: 0.0099\n",
      "episode: 470/5000, score: 105678.0, e: 0.0099\n",
      "episode: 471/5000, score: 106402.0, e: 0.0099\n",
      "episode: 472/5000, score: 105884.0, e: 0.0099\n",
      "episode: 473/5000, score: 105608.0, e: 0.0099\n",
      "episode: 474/5000, score: 105808.0, e: 0.0099\n",
      "episode: 475/5000, score: 103530.0, e: 0.0099\n",
      "episode: 476/5000, score: 105590.0, e: 0.0099\n",
      "episode: 477/5000, score: 106154.0, e: 0.0099\n",
      "episode: 478/5000, score: 104767.0, e: 0.0099\n",
      "episode: 479/5000, score: 104733.0, e: 0.0099\n",
      "episode: 480/5000, score: 105518.0, e: 0.0099\n",
      "episode: 481/5000, score: 105738.0, e: 0.0099\n",
      "episode: 482/5000, score: 106167.0, e: 0.0099\n",
      "episode: 483/5000, score: 104448.0, e: 0.0099\n",
      "episode: 484/5000, score: 105419.0, e: 0.0099\n",
      "episode: 485/5000, score: 105574.0, e: 0.0099\n",
      "episode: 486/5000, score: 105421.0, e: 0.0099\n",
      "episode: 487/5000, score: 105113.0, e: 0.0099\n",
      "episode: 488/5000, score: 106645.0, e: 0.0099\n",
      "episode: 489/5000, score: 105949.0, e: 0.0099\n",
      "episode: 490/5000, score: 105130.0, e: 0.0099\n",
      "episode: 491/5000, score: 105080.0, e: 0.0099\n",
      "episode: 492/5000, score: 105593.0, e: 0.0099\n",
      "episode: 493/5000, score: 105704.0, e: 0.0099\n",
      "episode: 494/5000, score: 105925.0, e: 0.0099\n",
      "episode: 495/5000, score: 105175.0, e: 0.0099\n",
      "episode: 496/5000, score: 105693.0, e: 0.0099\n",
      "episode: 497/5000, score: 107200.0, e: 0.0099\n",
      "episode: 498/5000, score: 105106.0, e: 0.0099\n",
      "episode: 499/5000, score: 105420.0, e: 0.0099\n",
      "episode: 500/5000, score: 105536.0, e: 0.0099\n",
      "episode: 501/5000, score: 105788.0, e: 0.0099\n",
      "episode: 502/5000, score: 105661.0, e: 0.0099\n",
      "episode: 503/5000, score: 105258.0, e: 0.0099\n",
      "episode: 504/5000, score: 105199.0, e: 0.0099\n",
      "episode: 505/5000, score: 104924.0, e: 0.0099\n",
      "episode: 506/5000, score: 104603.0, e: 0.0099\n",
      "episode: 507/5000, score: 105397.0, e: 0.0099\n",
      "episode: 508/5000, score: 106000.0, e: 0.0099\n",
      "episode: 509/5000, score: 105518.0, e: 0.0099\n",
      "episode: 510/5000, score: 105020.0, e: 0.0099\n",
      "episode: 511/5000, score: 104986.0, e: 0.0099\n",
      "episode: 512/5000, score: 104951.0, e: 0.0099\n",
      "episode: 513/5000, score: 105523.0, e: 0.0099\n",
      "episode: 514/5000, score: 105851.0, e: 0.0099\n",
      "episode: 515/5000, score: 107490.0, e: 0.0099\n",
      "episode: 516/5000, score: 106141.0, e: 0.0099\n",
      "episode: 517/5000, score: 105185.0, e: 0.0099\n",
      "episode: 518/5000, score: 105030.0, e: 0.0099\n",
      "episode: 519/5000, score: 104373.0, e: 0.0099\n",
      "episode: 520/5000, score: 104506.0, e: 0.0099\n",
      "episode: 521/5000, score: 105370.0, e: 0.0099\n",
      "episode: 522/5000, score: 105906.0, e: 0.0099\n",
      "episode: 523/5000, score: 105080.0, e: 0.0099\n",
      "episode: 524/5000, score: 105477.0, e: 0.0099\n",
      "episode: 525/5000, score: 104523.0, e: 0.0099\n",
      "episode: 526/5000, score: 105768.0, e: 0.0099\n",
      "episode: 527/5000, score: 105234.0, e: 0.0099\n",
      "episode: 528/5000, score: 106023.0, e: 0.0099\n",
      "episode: 529/5000, score: 105582.0, e: 0.0099\n",
      "episode: 530/5000, score: 105635.0, e: 0.0099\n",
      "episode: 531/5000, score: 105589.0, e: 0.0099\n",
      "episode: 532/5000, score: 105323.0, e: 0.0099\n",
      "episode: 533/5000, score: 106384.0, e: 0.0099\n",
      "episode: 534/5000, score: 105024.0, e: 0.0099\n",
      "episode: 535/5000, score: 106360.0, e: 0.0099\n",
      "episode: 536/5000, score: 106707.0, e: 0.0099\n",
      "episode: 537/5000, score: 104730.0, e: 0.0099\n"
     ]
    }
   ],
   "source": [
    "for e in range(EPISODES):\n",
    "    state = env.reset()\n",
    "    state = state.values.reshape([1, state_size])\n",
    "    while env.enough_data_provided():\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step((action, 100, 3)) # build these parameters into the NN model\n",
    "        # reward = reward if not done else -10\n",
    "        next_state = next_state.values.reshape([1, state_size])\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        \n",
    "    agent.update_target_model()\n",
    "    print(\"episode: {}/{}, score: {}, e: {:.2}\".format(e, EPISODES, env.score(), agent.epsilon))\n",
    "    \n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.replay(batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
